ML的性能在很大程度上取决于数据表示或特征的选择[6]。 ML算法的普遍性取决于数据集，数据集也间接依赖于表示数据集的显着结构的特征。通过识别突出特征，特征选择有助于提高ML的性能。它基本上选择不同的特征和数据子集，并以不同的粒度级别聚合它们，这有助于减少大数据量。然而，特征工程需要先前的领域知识和人类的聪明才智，并且通常是劳动密集型的[6]。为了解决当前特征工程算法在处理大数据时的弱点，已经提出了各种解决方案，例如分布式特征选择[25];低秩矩阵近似（例如，标准Nystr？m方法[26]）;表示学习通过学习一般先验[6]使学习算法减少对特征工程的依赖;用于超高维特征选择的自适应特征缩放方案，其迭代地激活一组特征并解决多个核学习子问题的序列[27];基于谱图理论的统一的特征选择框架，能够为监督和非监督特征选择生成算法族[28];分类前的模糊聚类，其中分组以群组为中心实现，然后通过减少数据进行去聚类和分类[29];并且减小了数据维度和体积的大小（例如，随机森林前向选择排名和随机森林后退消除排名[30]，以及具有所选特征的语言对冲神经模糊分类器[31]）。最近，基于深度神经网络的自动编码已被证明在学习视频，音频和文本功能方面非常有效[32,33]