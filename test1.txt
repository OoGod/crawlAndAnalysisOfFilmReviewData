ML可以在多个维度上表征：学习反馈的性质，学习任务的目标和数据可用性的时间。因此，我们提出了ML的多维分类，如图2所示
根据学习系统可用反馈的性质，ML可分为三种主要类型：监督学习，无监督学习和强化学习[5]。在超级学习中，学习系统提供了输入 - 输出对的示例，目标是学习将输入映射到输出的功能。在无监督学习中，系统没有提供明确的反馈或期望的输出，并且目标是揭示输入中的模式。与无监督学习一样，强化学习系统没有呈现输入 - 输出对。与监督学习一样，强化学习也会对其以前的经验给予反馈。然而，与监督学习不同，强化学习中的反馈是与行动相关的奖励或惩罚，而不是期望的输出或次优动作的明确校正。半监督学习落在有监督和无监督学习之间，其中系统呈现有少量输入 - 输出对和大量未注释的输入。半监督学习的目标与监督学习类似，只是它从注释和未注释的数据中学习。
基于学习目标是使用输入特征还是特征本身的特定任务，ML可以分为表征学习和任务学习。代表性学习旨在学习新的数据表示，以便在构建分类器或其他预先判断器时更容易提取有用的信息[6]。良好的表现是解开变异的潜在因素的表现。在概率模型的情况下，通常可以捕获观测输出的潜在探索因子的后验分布[6]。表示学习通常与密度估计和维数减少纠缠在一起。密度估计找到随机变量的下位概率密度函数。维度缩减将输入从高维空间映射到低维空间。在代表性学习中建立明确的目标或目标通常很困难。相反，任务学习通常具有期望的输出，因此被分类为分类，回归和聚类。在分类中，ML技术产生一种模型，该模型将看不见的输入分配给一个或多个预定义的类。回归与分类的不同之处在于其输出是连续的而不是离散的。聚类产生数据组，并且这些组事先不知道，这与分类不同。传统上，分类和回归被称为超级学习，而聚类被称为无监督学习。他们的代表性算法也显示在图2中
基于使训练数据可用的时间（例如，训练数据是一次全部可用还是一次一个），ML可以分为批量学习和在线学习。批量学习通过学习整个训练数据来生成模型，而在线学习基于每个新输入更新模型。批量学习算法假定数据是独立的并且从相同的概率分布中识别分布或抽取，这通常不被实际数据所满足。在线学习通常不对数据做出统计假设[7]。虽然预期批量学习算法可以概括，但是没有关于在线学习的概括的概念，因为该算法仅被期望准确地预测它作为输入接收的示例的标签[7]。当在整个数据集上进行训练和/或随着时间的推移生成数据并且学习系统需要适应数据中的新模式时，在计算上不可行时使用在线学习。
每个ML算法可以分为多个维度。例如，传统的决策树属于监督批量学习算法。
2.2。大数据
大数据的特征在于五个维度：数量（数量/数据量），速度（数据生成速度），种类（数据的类型，性质和格式），准确性（捕获数据的可信度/质量）和价值（见解和影响）。我们将五个维度组织成一个堆栈，包括从底部开始的大，数据和值层（参见图3）。大层是最基础的，数据层是大数据的核心，价值方面是大数据实际应用的影响。较低层（例如，体积和速度）更多地依赖于技术进步，而较高层（例如，价值）更倾向于利用大数据的战略力量的应用。为了实现大数据分析的价值并有效地处理大数据，需要调整现有的ML范例和算法。
